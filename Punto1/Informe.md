**Dise√±o de la soluci√≥n**
 -Modelo matem√°tico del perceptr√≥n 

¬°Perfecto! Aqu√≠ tienes el contenido listo en formato `.md` para que solo lo **copies y pegues** en tu archivo `README.md`. Abajo te explico **c√≥mo y cu√°ndo tomar las capturas** correctamente para cumplir con el entregable.

---

## ‚úÖ Contenido completo para `README.md` (solo copiar y pegar)

````markdown
# üß† Simulaci√≥n de Perceptr√≥n con Agentes en MESA

---

## üéØ Objetivo

Simular el entrenamiento de un **perceptr√≥n simple** utilizando el paradigma de **agentes** en Python, mediante el framework **MESA**, para clasificar puntos 2D linealmente separables.

---

## üß† ¬øQu√© es un Perceptr√≥n?

El perceptr√≥n es un modelo matem√°tico de neurona artificial propuesto por Frank Rosenblatt en 1958. Es una t√©cnica de clasificaci√≥n supervisada que determina a qu√© clase pertenece un punto bas√°ndose en una **funci√≥n lineal**.

Funciona ajustando autom√°ticamente los pesos y el sesgo de una l√≠nea de decisi√≥n en funci√≥n del error cometido al clasificar los datos de entrenamiento.

---

## üõ†Ô∏è Implementaci√≥n con MESA

### üî∏ Paradigma: Programaci√≥n Basada en Agentes (ABM)

- Cada **agente** representa un punto en el plano 2D.
- El **modelo global** contiene los pesos del perceptr√≥n y entrena a trav√©s de iteraciones (steps).
- Los agentes no se mueven; su estado cambia si est√°n bien o mal clasificados.

### üî∏ Entradas:

- Coordenadas 2D aleatorias: \( x_1, x_2 \)
- Etiquetas asignadas seg√∫n una l√≠nea real:  
  `label = 1 if x2 > 0.5 * x1 + 0.2 else 0`

### üî∏ Entrenamiento:

- En cada step, los agentes calculan su salida con la f√≥rmula del perceptr√≥n.
- Si hay error, se actualizan los pesos globales seg√∫n la regla de aprendizaje.

---

## üßÆ Modelo Matem√°tico

El perceptr√≥n simple calcula la salida:

```latex
$$
y = 
\begin{cases}
1 & \text{si } w_1 x_1 + w_2 x_2 + b > 0 \\
0 & \text{en otro caso}
\end{cases}
$$
````

Regla de actualizaci√≥n:

```latex
$$
\text{error} = \hat{y} - y
$$

$$
w_1 \leftarrow w_1 + \eta \cdot \text{error} \cdot x_1
$$

$$
w_2 \leftarrow w_2 + \eta \cdot \text{error} \cdot x_2
$$

$$
b \leftarrow b + \eta \cdot \text{error}
$$
```

---

## üìä Visualizaci√≥n

* **Puntos en pantalla**:

  * Verdes: bien clasificados
  * Naranjas: mal clasificados
* **Gr√°fico de error**: muestra la evoluci√≥n del error promedio por step
* **Frontera de decisi√≥n**: se actualiza visualmente durante el entrenamiento

---

## üì∑ Capturas de pantalla

### üñºÔ∏è Entrenamiento del Perceptr√≥n

> Muestra la pantalla **cuando la simulaci√≥n lleva unos 10 a 30 pasos** y todav√≠a hay varios puntos mal clasificados (de color naranja). El gr√°fico de error a√∫n no ha llegado a 0.

![Entrenamiento en curso](capturas/entrenamiento.png)

---

### ‚úÖ Clasificaci√≥n final

> Muestra la pantalla cuando el error promedio lleg√≥ a 0 o muy cerca, y **todos los puntos est√°n verdes**. Idealmente, despu√©s de 30-100 steps.

![Clasificaci√≥n final](capturas/final.png)

---

## üìà Resultados

* El perceptr√≥n logr√≥ reducir el error promedio a cerca de 0 despu√©s de varias iteraciones.
* La l√≠nea de decisi√≥n aprendida logr√≥ separar correctamente los puntos, validando que los datos eran linealmente separables.
* La visualizaci√≥n permiti√≥ observar el proceso de aprendizaje paso a paso.

---

## ‚úÖ Conclusi√≥n

El modelo implementado demuestra c√≥mo un perceptr√≥n simple puede aprender a clasificar datos de forma efectiva. Adem√°s, la simulaci√≥n basada en agentes permite visualizar el aprendizaje de manera din√°mica e interactiva, facilitando la comprensi√≥n del funcionamiento interno del algoritmo.
